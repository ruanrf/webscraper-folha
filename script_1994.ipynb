{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''imports'''\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entre a URL da primeira página da busca: https://search.folha.uol.com.br/search?q=copa+do+mundo+futebol&periodo=personalizado&sd=12%2F06%2F1994&ed=12%2F07%2F1994&site=todos\n",
      "Quantos resultados existem nessa busca? 320\n",
      "Listagem de matérias realizada! Matérias adicionadas à lista: 316\n"
     ]
    }
   ],
   "source": [
    "'''entrada da primeira página de resultado de busca e geração de lista de matérias'''\n",
    "\n",
    "url_input = str(input('Entre a URL da primeira página da busca: '))\n",
    "qtd_paginas = int(np.ceil(int(input('Quantos resultados existem nessa busca? '))/25))\n",
    "\n",
    "materias=[] # lista para armazenar as URLs das matérias\n",
    "re_compile = 'http://www1.folha.uol.com.br/fsp/'\n",
    "# geração das urls de página de busca:\n",
    "url_busca = [str(url_input)+'&sr='+str((i*25)+1) for i in range(qtd_paginas)]\n",
    "    \n",
    "# laço para varrer as páginas de busca e empilhar as urls na lista materias:\n",
    "for url in url_busca:\n",
    "    conteudo_bs = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
    "\n",
    "    # busca a url das matérias dentro da página de busca (apenas contendo www1..../fsp/):\n",
    "    for materia in conteudo_bs.findAll('a', attrs={'href': re.compile(re_compile)}):\n",
    "        materias.append(materia.get('href'))\n",
    "        \n",
    "print('Listagem de matérias realizada! Matérias adicionadas à lista: '+ str(len(materias)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''abre matérias da lista, busca, limpa e salva o título em uma lista e o texto em outra'''\n",
    "\n",
    "titulos=[] # lista dos títulos das matérias\n",
    "textos=[] # lista contendo o texto das matérias\n",
    "\n",
    "# laço abrindo matéria por matéria da lista materias:\n",
    "for mat in materias:\n",
    "    \n",
    "    materia_bs = str(BeautifulSoup(requests.get(mat).content)).replace('<br/>', ' ')\n",
    "\n",
    "    # busca o título e armazena na lista titulos:\n",
    "    titulos.append(BeautifulSoup(materia_bs).find('title').text[19:-11])\n",
    "\n",
    "    # condição para armazenar matérias específicas; algumas não possuem Texto Anterior: no corpo\n",
    "    if 'Texto Anterior:' in materia_bs:\n",
    "        t1 = BeautifulSoup(materia_bs).find(text=re.compile('Texto Anterior:'))\n",
    "        textos.append(BeautifulSoup(t1[:t1.index('Texto Anterior')],'html.parser'))\n",
    "    elif 'Próximo Texto:' in materia_bs:\n",
    "        t1 = BeautifulSoup(materia_bs).find(text=re.compile('Próximo Texto:'))\n",
    "        textos.append(BeautifulSoup(t1[:t1.index('Próximo ')],'html.parser'))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qual o diretório onde serão criados os arquivos? Colocar o endereço com a \"\\\" no final: C:\\Users\\ruan_\\Desktop\\Projeto\\textos\\1994\\\n"
     ]
    }
   ],
   "source": [
    "'''cria os arquivos e armazena neles o título seguido do corpo de texto'''\n",
    "\n",
    "arquivos=[] # inicia a lista para criação de arquivos e armazenamento dos textos\n",
    "dir=input(str('Qual o diretório onde serão criados os arquivos? Colocar o endereço com a \"\\\\\" no final: '))\n",
    "size=len(materias)\n",
    "\n",
    "for i in range(size):\n",
    "    arquivo_nome='1994_'+str(i+1)+'.txt'\n",
    "    arquivo=open(dir+arquivo_nome,'w+', encoding='utf-8')\n",
    "    empilhado=open(dir+'1994_empilhado.txt','a', encoding='utf-8')\n",
    "    arquivo.write(str(titulos[i])+str(textos[i]))\n",
    "    empilhado.write(str(titulos[i])+str(textos[i]))\n",
    "    arquivo.close()\n",
    "    empilhado.close()\n",
    "    arquivos.append(arquivo_nome)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
